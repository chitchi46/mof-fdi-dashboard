# 大規模データのパフォーマンス最適化

## 目的（Goal）
- 10万行以上・多数の指標/地域でも、パイプラインとダッシュボードの応答性を維持（効率的な処理/キャッシュ/レンダリング）。

## 範囲（Scope）
- 現行パイプライン/UIのベンチを取り、基準値を確立。
- サマリに対するデータ削減（ダウンサンプル/ウィンドウ）とキャッシュを導入。
- 重い計算をメインスレッドから分離（Web Worker）し、描画ループを最適化。
- 性能回帰を監視するための計装を追加。
- 対象外: 分散処理やストレージ再設計。

## 成果物（Deliverables）
- ベンチマークレポート（パイプライン時間、メモリ、UIフレームタイム）。
- 最適化された集計層（プリ計算キューブ、フィルタキーによるメモ化）。
- 高密度時系列のLTTB等のダウンサンプリング＋必要時に生データ表示。
- JSON 解析/集計のWeb Worker化（UIスレッドを保護）。
- 性能ダッシュボード/ログ（簡易メトリクス、`stats.json` 任意）。
- 自動パフォーマンステスト（CIジョブ/手動スクリプト）。

## 作業分解（Work Breakdown）
1. ベンチマーク
   - 大規模合成データを作成（指標/地域/年の多様性）し、時間/メモリを計測。
   - ブラウザDevToolsでロード/フィルタ変更/エクスポートをプロファイル。
2. パイプライン最適化
   - 数値パースのベクトル化、冗長変換の排除。
   - 中間テーブル（例: 正規化DF）をキャッシュしエクスポート間で再利用。
3. サマリ/データ層
   - 年×系列×地域の多次元キャッシュを構築し再計算を回避。
   - 集計済み/生スライスを用意しUIが粒度を選べるようにする。
4. ダウンサンプリング/タイル
   - N点超の時系列にLTTBやパーセンタイル縮約を適用。
   - 表示は縮約、DLはフル解像度を選択可能にする。
5. 並行処理/Worker
   - 重い解析/集計をWorkerへ。メッセージプロトコル、進捗/キャンセル対応。
6. レンダリング効率
   - 可視化レイヤ（`.plans/visual-quality-upgrade.md`）のCPU使用をプロファイル。
   - 系列が多い場合の凡例/ツールチップを仮想化。
7. 監視とテスト
   - `pytest-benchmark` + Playwright のperfハーネスでローカル/CI実行。
   - 基準と閾値を文書化し、許容超過で失敗させる。

## 依存関係（Dependencies）
- 可視化アップグレード計画。
- CSVエクスポート計画（キャッシュ戦略の整合）。

## リスクと対策（Risks & Mitigations）
- 早すぎる最適化 → 基準値に基づいて優先度を決定。
- 複雑なキャッシュ → ハッシュによる無効化とヒット/ミスの計測。
- Workerオーバーヘッド → 処理のバッチ化で相殺。

## 未決事項（Open Questions）
- モバイルでの性能要件。
- キャッシュをセッション間で保持（IndexedDB）するか、セッション内メモリに限定するか。

## 受け入れ基準（Acceptance Criteria）
- パイプラインが10万行を≤30秒、フィルタ変更は<200ms。
- ダウンサンプルで視認性を保ちつつレンダ時間を≥50%短縮（ストレスデータ）。
- 性能メトリクスを追跡・文書化し、回帰テストが存在する。
